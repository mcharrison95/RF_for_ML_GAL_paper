{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datascience.stackexchange.com/questions/40067/confusion-matrix-three-classes-python/40068 \n",
    "#confusion matrix graphics code\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True Growth on Sucrose')\n",
    "    plt.xlabel('Predicted Growth on Sucrose')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the XgBoost rf pipeline into a function so I could plug in different datasets and predicting variables quickly\n",
    "def quick_rf(filelist, predicting, dropping):\n",
    "    import pandas as pd\n",
    "    results_dict = {}\n",
    "    df = pd.read_csv(filelist[0], index_col=0)\n",
    "    if len(filelist) > 1: \n",
    "        for i in range(1, len(filelist)): \n",
    "            newdf = pd.read_csv(filelist[i], index_col=0)\n",
    "            df = pd.concat([newdf, df.set_index(newdf.index)], axis=1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "    from xgboost import XGBRFClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import xgboost as xgb\n",
    "    from sklearn.utils import compute_sample_weight\n",
    "    import matplotlib.pyplot as plt\n",
    "    df = df.dropna(subset=[predicting])\n",
    "    input_ed = df.drop(dropping, axis=1)\n",
    "    ml_input = np.array(input_ed) #array of input\n",
    "    output = np.array(df[predicting]) #array of output\n",
    "    model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs=8)\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    y_pred = cross_val_predict(model, ml_input, output, cv=10)\n",
    "    tn, fp, fn, tp = confusion_matrix(output, y_pred).ravel()\n",
    "    print('Precision:', tp/(tp+fp))\n",
    "    model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs=8)\n",
    "    xtrain, xtest, ytrain, ytest=train_test_split(ml_input, output, test_size=0.10)\n",
    "    class_weights_training = compute_sample_weight('balanced', ytrain)\n",
    "    model.fit(xtrain, ytrain, sample_weight=class_weights_training) \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, ml_input, output, scoring='balanced_accuracy', cv=cv)\n",
    "    print('Balanced Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)), '\\n')\n",
    "    header = list(input_ed.columns)\n",
    "    importance_list = []\n",
    "    importances = list(model.feature_importances_)\n",
    "    o = 0\n",
    "    m = 0\n",
    "    for i in model.feature_importances_:\n",
    "        results_dict[header[o]] = i\n",
    "        o = o + 1\n",
    "    print(max(results_dict, key = results_dict.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig 2: predict growth on substates from KEGG data\n",
    "predictinglist = ['C29_D.Mannitol', 'C39_Succinate', 'D.Glucose__Fermentation', 'C32_D.Glucono.1_5.lactone', 'C12_a_a.Trehalose', 'C6_D.Xylose', 'C2_D.Galactose', 'C14_Cellobiose', 'C26_Xylitol', 'C10_Sucrose', 'C15_Salicin', 'C25_Ribitol', 'C11_Maltose', 'C40_Citrate', 'C35_D.Gluconate', 'C3_L.Sorbose', 'C20_Melezitose', 'C13_Me_a.D.Glucoside', 'O1_Cycloheximide_0.01_', 'C33_2.Keto.D.Gluconate', 'C38_DL.Lactate', 'C5_D.Ribose', 'C4_D.Glucosamine', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C24_Erythritol', 'C19_Raffinose', 'C9_L.Rhamnose', 'C22_Starch']\n",
    "dropping = ['D.Glucose__Fermentation', 'D.Galactose__Fermentation', 'Maltose__Fermentation', 'Me_a.D.Glucoside__Fermentation', 'Sucrose__Fermentation', 'a_a.Trehalose__Fermentation', 'Melibiose__Fermentation', 'Lactose__Fermentation', 'Cellobiose__Fermentation', 'Melezitose__Fermentation', 'Raffinose__Fermentation', 'Inulin__Fermentation', 'Starch__Fermentation', 'D.Xylose__Fermentation', 'X_50__D.Glucose__O4_', 'X_60__D.Glucose__O5_', 'Starch_formation__M1_', 'Acid_acetic_production__M2_', 'Urea_hydrolysis__M3_', 'Diazonium_Blue_B_reaction__M4_', 'Methanol__assimilation', 'Ethanol__assimilation', 'C1_D.Glucose', 'C2_D.Galactose', 'C3_L.Sorbose', 'C4_D.Glucosamine', 'C5_D.Ribose', 'C6_D.Xylose', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C9_L.Rhamnose', 'C10_Sucrose', 'C11_Maltose', 'C12_a_a.Trehalose', 'C13_Me_a.D.Glucoside', 'C14_Cellobiose', 'C15_Salicin', 'C16_Arbutin', 'C17_Melibiose', 'C18_Lactose', 'C19_Raffinose', 'C20_Melezitose', 'C21_Inulin', 'C22_Starch', 'C23_Glycerol', 'C24_Erythritol', 'C25_Ribitol', 'C26_Xylitol', 'C27_L.Arabinitol', 'C28_D.Glucitol', 'C29_D.Mannitol', 'C30_Galactitol', 'C31_myo.Inositol', 'C32_D.Glucono.1_5.lactone', 'C33_2.Keto.D.Gluconate', 'C34_5.Keto.D.Gluconate', 'C35_D.Gluconate', 'C36_D.Glucuronate', 'C37_D.Galacturonate', 'C38_DL.Lactate', 'C39_Succinate', 'C40_Citrate', 'C43_Propane_1_2_diol', 'C44_Butane_2_3_diol', 'C45_Quinic_acid', 'C46_D.glucarate', 'C47_D.Galactonate', 'C48_Palatinose', 'C49_Levulinate', 'C50_L.Malic_acid', 'C51_L.Tartaric_acid', 'C52_D.Tartaric_acid', 'C53_meso.Tartaric_acid', 'C54_Galactaric_acid', 'C55_Uric_acid', 'C56_Gentobiose', 'C57_Ethylene_glycol', 'C58_Tween_40', 'C59_Tween_60', 'C60_Tween_80', 'N1_Nitrate', 'N2_Nitrite', 'N3_Ethylamine', 'N4_L.Lysine', 'N5_Cadaverine', 'N6_Creatine', 'N7_Creatinine', 'N8_Glucosamine', 'N9_Imidazole', 'N10_D.Tryptophan', 'N11_D.Proline', 'N12_Putrescine', 'V1_w_o_vitamins', 'V2_w_o_myo.Inositol', 'V3_w_o_Pantothenate', 'V4_w_o_Biotin', 'V5_w_o_Thiamin', 'V6_w_o_Biotin___Thiamin', 'V7_w_o_Pyridoxine', 'V8_w_o_Pyridoxine___Thiamin', 'V9_w_o_Niacin', 'V10_w_o_PABA', 'O1_Cycloheximide_0.01_', 'O2_Cycloheximide_0.1_', 'O3_Acetic_acid_1_', 'O6_10__NaCl', 'O7_16__NaCl', 'O8_Growth_at_pH_3', 'O9_Growth_at_pH_9.5', 'O10_Fluconazole', 'at_4_C', 'at_12_C', 'at_15_C', 'at_18_C', 'at_21_C', 'at_25_C', 'at_30_C', 'at_35_C', 'at_37_C', 'at_40_C', 'at_42_C', 'at_45_C']\n",
    "#input for RF\n",
    "filelist = ['final_KEGG_genomic_s2.csv','final_metabolic_table_s3.csv']\n",
    "\n",
    "for predicting in predictinglist:\n",
    "    print(predicting)\n",
    "    quick_rf(filelist, predicting, dropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig 2: predicting growth on substrates from KEGG + interpro data\n",
    "#predict growth on substates from KEGG data\n",
    "predictinglist = ['C29_D.Mannitol', 'C39_Succinate', 'D.Glucose__Fermentation', 'C32_D.Glucono.1_5.lactone', 'C12_a_a.Trehalose', 'C6_D.Xylose', 'C2_D.Galactose', 'C14_Cellobiose', 'C26_Xylitol', 'C10_Sucrose', 'C15_Salicin', 'C25_Ribitol', 'C11_Maltose', 'C40_Citrate', 'C35_D.Gluconate', 'C3_L.Sorbose', 'C20_Melezitose', 'C13_Me_a.D.Glucoside', 'O1_Cycloheximide_0.01_', 'C33_2.Keto.D.Gluconate', 'C38_DL.Lactate', 'C5_D.Ribose', 'C4_D.Glucosamine', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C24_Erythritol', 'C19_Raffinose', 'C9_L.Rhamnose', 'C22_Starch']\n",
    "dropping = ['D.Glucose__Fermentation', 'D.Galactose__Fermentation', 'Maltose__Fermentation', 'Me_a.D.Glucoside__Fermentation', 'Sucrose__Fermentation', 'a_a.Trehalose__Fermentation', 'Melibiose__Fermentation', 'Lactose__Fermentation', 'Cellobiose__Fermentation', 'Melezitose__Fermentation', 'Raffinose__Fermentation', 'Inulin__Fermentation', 'Starch__Fermentation', 'D.Xylose__Fermentation', 'X_50__D.Glucose__O4_', 'X_60__D.Glucose__O5_', 'Starch_formation__M1_', 'Acid_acetic_production__M2_', 'Urea_hydrolysis__M3_', 'Diazonium_Blue_B_reaction__M4_', 'Methanol__assimilation', 'Ethanol__assimilation', 'C1_D.Glucose', 'C2_D.Galactose', 'C3_L.Sorbose', 'C4_D.Glucosamine', 'C5_D.Ribose', 'C6_D.Xylose', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C9_L.Rhamnose', 'C10_Sucrose', 'C11_Maltose', 'C12_a_a.Trehalose', 'C13_Me_a.D.Glucoside', 'C14_Cellobiose', 'C15_Salicin', 'C16_Arbutin', 'C17_Melibiose', 'C18_Lactose', 'C19_Raffinose', 'C20_Melezitose', 'C21_Inulin', 'C22_Starch', 'C23_Glycerol', 'C24_Erythritol', 'C25_Ribitol', 'C26_Xylitol', 'C27_L.Arabinitol', 'C28_D.Glucitol', 'C29_D.Mannitol', 'C30_Galactitol', 'C31_myo.Inositol', 'C32_D.Glucono.1_5.lactone', 'C33_2.Keto.D.Gluconate', 'C34_5.Keto.D.Gluconate', 'C35_D.Gluconate', 'C36_D.Glucuronate', 'C37_D.Galacturonate', 'C38_DL.Lactate', 'C39_Succinate', 'C40_Citrate', 'C43_Propane_1_2_diol', 'C44_Butane_2_3_diol', 'C45_Quinic_acid', 'C46_D.glucarate', 'C47_D.Galactonate', 'C48_Palatinose', 'C49_Levulinate', 'C50_L.Malic_acid', 'C51_L.Tartaric_acid', 'C52_D.Tartaric_acid', 'C53_meso.Tartaric_acid', 'C54_Galactaric_acid', 'C55_Uric_acid', 'C56_Gentobiose', 'C57_Ethylene_glycol', 'C58_Tween_40', 'C59_Tween_60', 'C60_Tween_80', 'N1_Nitrate', 'N2_Nitrite', 'N3_Ethylamine', 'N4_L.Lysine', 'N5_Cadaverine', 'N6_Creatine', 'N7_Creatinine', 'N8_Glucosamine', 'N9_Imidazole', 'N10_D.Tryptophan', 'N11_D.Proline', 'N12_Putrescine', 'V1_w_o_vitamins', 'V2_w_o_myo.Inositol', 'V3_w_o_Pantothenate', 'V4_w_o_Biotin', 'V5_w_o_Thiamin', 'V6_w_o_Biotin___Thiamin', 'V7_w_o_Pyridoxine', 'V8_w_o_Pyridoxine___Thiamin', 'V9_w_o_Niacin', 'V10_w_o_PABA', 'O1_Cycloheximide_0.01_', 'O2_Cycloheximide_0.1_', 'O3_Acetic_acid_1_', 'O6_10__NaCl', 'O7_16__NaCl', 'O8_Growth_at_pH_3', 'O9_Growth_at_pH_9.5', 'O10_Fluconazole', 'at_4_C', 'at_12_C', 'at_15_C', 'at_18_C', 'at_21_C', 'at_25_C', 'at_30_C', 'at_35_C', 'at_37_C', 'at_40_C', 'at_42_C', 'at_45_C']\n",
    "#input for RF\n",
    "filelist = ['final_interpro_genomic_s1.csv', 'final_KEGG_genomic_s2.csv', 'final_metabolic_table_s3.csv']\n",
    "\n",
    "for predicting in predictinglist:\n",
    "    print(predicting)\n",
    "    quick_rf(filelist, predicting, dropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig 2: predicting growth on substates by metabolic data\n",
    "#certain ones of these I had to add additional dropped features manually, like galactos fermentation for galactose\n",
    "predictinglist = ['C29_D.Mannitol', 'C39_Succinate', 'D.Glucose__Fermentation', 'C32_D.Glucono.1_5.lactone', 'C12_a_a.Trehalose', 'C6_D.Xylose', 'C2_D.Galactose', 'C14_Cellobiose', 'C26_Xylitol', 'C10_Sucrose', 'C15_Salicin', 'C25_Ribitol', 'C11_Maltose', 'C40_Citrate', 'C35_D.Gluconate', 'C3_L.Sorbose', 'C20_Melezitose', 'C13_Me_a.D.Glucoside', 'O1_Cycloheximide_0.01_', 'C33_2.Keto.D.Gluconate', 'C38_DL.Lactate', 'C5_D.Ribose', 'C4_D.Glucosamine', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C24_Erythritol', 'C19_Raffinose', 'C9_L.Rhamnose', 'C22_Starch']\n",
    "#input for RF\n",
    "filelist = ['final_metabolic_table_s3.csv']\n",
    "\n",
    "for predicting in predictinglist:\n",
    "    dropping = predicting\n",
    "    print(predicting)\n",
    "    quick_rf(filelist, predicting, predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig 2: predicting growth on substates by environmental data\n",
    "predictinglist = ['C29_D.Mannitol', 'C39_Succinate', 'D.Glucose__Fermentation', 'C32_D.Glucono.1_5.lactone', 'C12_a_a.Trehalose', 'C6_D.Xylose', 'C2_D.Galactose', 'C14_Cellobiose', 'C26_Xylitol', 'C10_Sucrose', 'C15_Salicin', 'C25_Ribitol', 'C11_Maltose', 'C40_Citrate', 'C35_D.Gluconate', 'C3_L.Sorbose', 'C20_Melezitose', 'C13_Me_a.D.Glucoside', 'O1_Cycloheximide_0.01_', 'C33_2.Keto.D.Gluconate', 'C38_DL.Lactate', 'C5_D.Ribose', 'C4_D.Glucosamine', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C24_Erythritol', 'C19_Raffinose', 'C9_L.Rhamnose', 'C22_Starch']\n",
    "#input for RF\n",
    "filelist = ['final_env_table_s4.csv', 'final_metabolic_table_s3.csv']\n",
    "dropping = ['D.Glucose__Fermentation', 'D.Galactose__Fermentation', 'Maltose__Fermentation', 'Me_a.D.Glucoside__Fermentation', 'Sucrose__Fermentation', 'a_a.Trehalose__Fermentation', 'Melibiose__Fermentation', 'Lactose__Fermentation', 'Cellobiose__Fermentation', 'Melezitose__Fermentation', 'Raffinose__Fermentation', 'Inulin__Fermentation', 'Starch__Fermentation', 'D.Xylose__Fermentation', 'X_50__D.Glucose__O4_', 'X_60__D.Glucose__O5_', 'Starch_formation__M1_', 'Acid_acetic_production__M2_', 'Urea_hydrolysis__M3_', 'Diazonium_Blue_B_reaction__M4_', 'Methanol__assimilation', 'Ethanol__assimilation', 'C1_D.Glucose', 'C2_D.Galactose', 'C3_L.Sorbose', 'C4_D.Glucosamine', 'C5_D.Ribose', 'C6_D.Xylose', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C9_L.Rhamnose', 'C10_Sucrose', 'C11_Maltose', 'C12_a_a.Trehalose', 'C13_Me_a.D.Glucoside', 'C14_Cellobiose', 'C15_Salicin', 'C16_Arbutin', 'C17_Melibiose', 'C18_Lactose', 'C19_Raffinose', 'C20_Melezitose', 'C21_Inulin', 'C22_Starch', 'C23_Glycerol', 'C24_Erythritol', 'C25_Ribitol', 'C26_Xylitol', 'C27_L.Arabinitol', 'C28_D.Glucitol', 'C29_D.Mannitol', 'C30_Galactitol', 'C31_myo.Inositol', 'C32_D.Glucono.1_5.lactone', 'C33_2.Keto.D.Gluconate', 'C34_5.Keto.D.Gluconate', 'C35_D.Gluconate', 'C36_D.Glucuronate', 'C37_D.Galacturonate', 'C38_DL.Lactate', 'C39_Succinate', 'C40_Citrate', 'C43_Propane_1_2_diol', 'C44_Butane_2_3_diol', 'C45_Quinic_acid', 'C46_D.glucarate', 'C47_D.Galactonate', 'C48_Palatinose', 'C49_Levulinate', 'C50_L.Malic_acid', 'C51_L.Tartaric_acid', 'C52_D.Tartaric_acid', 'C53_meso.Tartaric_acid', 'C54_Galactaric_acid', 'C55_Uric_acid', 'C56_Gentobiose', 'C57_Ethylene_glycol', 'C58_Tween_40', 'C59_Tween_60', 'C60_Tween_80', 'N1_Nitrate', 'N2_Nitrite', 'N3_Ethylamine', 'N4_L.Lysine', 'N5_Cadaverine', 'N6_Creatine', 'N7_Creatinine', 'N8_Glucosamine', 'N9_Imidazole', 'N10_D.Tryptophan', 'N11_D.Proline', 'N12_Putrescine', 'V1_w_o_vitamins', 'V2_w_o_myo.Inositol', 'V3_w_o_Pantothenate', 'V4_w_o_Biotin', 'V5_w_o_Thiamin', 'V6_w_o_Biotin___Thiamin', 'V7_w_o_Pyridoxine', 'V8_w_o_Pyridoxine___Thiamin', 'V9_w_o_Niacin', 'V10_w_o_PABA', 'O1_Cycloheximide_0.01_', 'O2_Cycloheximide_0.1_', 'O3_Acetic_acid_1_', 'O6_10__NaCl', 'O7_16__NaCl', 'O8_Growth_at_pH_3', 'O9_Growth_at_pH_9.5', 'O10_Fluconazole', 'at_4_C', 'at_12_C', 'at_15_C', 'at_18_C', 'at_21_C', 'at_25_C', 'at_30_C', 'at_35_C', 'at_37_C', 'at_40_C', 'at_42_C', 'at_45_C']\n",
    "\n",
    "\n",
    "for predicting in predictinglist:\n",
    "    print(predicting)\n",
    "    randomsample2(filelist, predicting, dropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 3: Predicting growth on galactose from KEGG Orthology data--repeated for Xylose and Sucrose too\n",
    "import pandas as pd\n",
    "\n",
    "#format input\n",
    "input1= 'final_KEGG_genomic_s2.csv'\n",
    "input2='final_metabolic_table_s3.csv'\n",
    "\n",
    "df1 = pd.read_csv(input1, index_col=0)\n",
    "df2 = pd.read_csv(input2, index_col=0)\n",
    "df = pd.concat([df1, df2.set_index(df1.index)], axis=1)\n",
    "#df = pd.read_csv(input2, index_col=0)\n",
    "\n",
    "\n",
    "#import modules needed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#define what we want to predict out of the dataset\n",
    "predicting = 'C2_D.Galactose'\n",
    "#drop NAs (species we didn't measure specialism/generalism) from the dataset\n",
    "df = df.dropna(subset=[predicting])\n",
    "\n",
    "#decide what other data you want to drop from the input, here I am dropping the predicted value\n",
    "dropping = ['D.Glucose__Fermentation', 'D.Galactose__Fermentation', 'Maltose__Fermentation', 'Me_a.D.Glucoside__Fermentation', 'Sucrose__Fermentation', 'a_a.Trehalose__Fermentation', 'Melibiose__Fermentation', 'Lactose__Fermentation', 'Cellobiose__Fermentation', 'Melezitose__Fermentation', 'Raffinose__Fermentation', 'Inulin__Fermentation', 'Starch__Fermentation', 'D.Xylose__Fermentation', 'X_50__D.Glucose__O4_', 'X_60__D.Glucose__O5_', 'Starch_formation__M1_', 'Acid_acetic_production__M2_', 'Urea_hydrolysis__M3_', 'Diazonium_Blue_B_reaction__M4_', 'Methanol__assimilation', 'Ethanol__assimilation', 'C1_D.Glucose', 'C2_D.Galactose', 'C3_L.Sorbose', 'C4_D.Glucosamine', 'C5_D.Ribose', 'C6_D.Xylose', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C9_L.Rhamnose', 'C10_Sucrose', 'C11_Maltose', 'C12_a_a.Trehalose', 'C13_Me_a.D.Glucoside', 'C14_Cellobiose', 'C15_Salicin', 'C16_Arbutin', 'C17_Melibiose', 'C18_Lactose', 'C19_Raffinose', 'C20_Melezitose', 'C21_Inulin', 'C22_Starch', 'C23_Glycerol', 'C24_Erythritol', 'C25_Ribitol', 'C26_Xylitol', 'C27_L.Arabinitol', 'C28_D.Glucitol', 'C29_D.Mannitol', 'C30_Galactitol', 'C31_myo.Inositol', 'C32_D.Glucono.1_5.lactone', 'C33_2.Keto.D.Gluconate', 'C34_5.Keto.D.Gluconate', 'C35_D.Gluconate', 'C36_D.Glucuronate', 'C37_D.Galacturonate', 'C38_DL.Lactate', 'C39_Succinate', 'C40_Citrate', 'C43_Propane_1_2_diol', 'C44_Butane_2_3_diol', 'C45_Quinic_acid', 'C46_D.glucarate', 'C47_D.Galactonate', 'C48_Palatinose', 'C49_Levulinate', 'C50_L.Malic_acid', 'C51_L.Tartaric_acid', 'C52_D.Tartaric_acid', 'C53_meso.Tartaric_acid', 'C54_Galactaric_acid', 'C55_Uric_acid', 'C56_Gentobiose', 'C57_Ethylene_glycol', 'C58_Tween_40', 'C59_Tween_60', 'C60_Tween_80', 'N1_Nitrate', 'N2_Nitrite', 'N3_Ethylamine', 'N4_L.Lysine', 'N5_Cadaverine', 'N6_Creatine', 'N7_Creatinine', 'N8_Glucosamine', 'N9_Imidazole', 'N10_D.Tryptophan', 'N11_D.Proline', 'N12_Putrescine', 'V1_w_o_vitamins', 'V2_w_o_myo.Inositol', 'V3_w_o_Pantothenate', 'V4_w_o_Biotin', 'V5_w_o_Thiamin', 'V6_w_o_Biotin___Thiamin', 'V7_w_o_Pyridoxine', 'V8_w_o_Pyridoxine___Thiamin', 'V9_w_o_Niacin', 'V10_w_o_PABA', 'O1_Cycloheximide_0.01_', 'O2_Cycloheximide_0.1_', 'O3_Acetic_acid_1_', 'O6_10__NaCl', 'O7_16__NaCl', 'O8_Growth_at_pH_3', 'O9_Growth_at_pH_9.5', 'O10_Fluconazole', 'at_4_C', 'at_12_C', 'at_15_C', 'at_18_C', 'at_21_C', 'at_25_C', 'at_30_C', 'at_35_C', 'at_37_C', 'at_40_C', 'at_42_C', 'at_45_C']\n",
    "input_ed = df.drop(dropping, axis=1)\n",
    "ml_input = np.array(input_ed) #array of input\n",
    "output = np.array(df[predicting]) #array of output\n",
    "print(output)\n",
    "\n",
    "#build your model \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "\n",
    "#use cross_val_predict to test the model and build the big confusion matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(model, ml_input, output, cv=10)\n",
    "conf_mat = confusion_matrix(output, y_pred)\n",
    "print(conf_mat)\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_mat, classes=['0','1'],\n",
    "                     title='Confusion matrix')\n",
    "plt.savefig(\"Confusion_Matrix.png\", dpi=200)\n",
    "\n",
    "\n",
    "#look specifically at which species are incorrectly and correctly predicted\n",
    "species_list = list(df.index)\n",
    "print('Incorrectly IDed  True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] != y_pred[i]:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "print('Correctly IDed   True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] == 1 and y_pred[i] == 1:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "\n",
    "header = list(input_ed.columns)\n",
    "\n",
    "# define the model again to re-test on a held out dataset, usually have  subsample=0.9, colsample_bynode=0.8, \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(ml_input, output, test_size=0.10)\n",
    "class_weights_training = compute_sample_weight('balanced', ytrain)\n",
    "#sample_weight=class_weights_training\n",
    "#model.fit(xtrain, ytrain) \n",
    "model.fit(xtrain, ytrain, sample_weight=class_weights_training) \n",
    "\n",
    "print('Mini_test')\n",
    "ypred = model.predict(xtest)\n",
    "cm = confusion_matrix(ytest,ypred)\n",
    "total = sum(cm[0]) + sum(cm[1])\n",
    "mis = cm[0][1] + cm[1][0]\n",
    "print('Misclassification rate:', mis/total)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=['0','1'],\n",
    "                     title='Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "#rebuild model yet again for the final big cross validation accuracy metrics with RepeatedStratifiedKFold\n",
    "classes_weights = compute_sample_weight('balanced', output)\n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "sample_weight=classes_weights\n",
    "model.fit(ml_input, output, sample_weight=classes_weights)\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, ml_input, output, scoring='accuracy', cv=cv)\n",
    "print(n_scores)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)), '\\n')\n",
    "\n",
    "\n",
    "#report feature importances in order of most important to least\n",
    "importance_list = []\n",
    "importances = list(model.feature_importances_)\n",
    "o = 0\n",
    "m = 0\n",
    "top10 = []\n",
    "for i in model.feature_importances_:\n",
    "    importance_list.append([i, header[o]])\n",
    "    o = o + 1\n",
    "for i in importance_list:\n",
    "    if i[0] == max(importances):\n",
    "        print(i[1], '\\t', i[0])\n",
    "        if m < 10:\n",
    "            top10.append(i[1])\n",
    "            m = m + 1\n",
    "            importances.remove(i[0])\n",
    "        else:\n",
    "            importances.remove(i[0])\n",
    "    else:\n",
    "        importance_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 3: Predicting growth on galactose from metabolic data--repeated for sucrose and xylose too\n",
    "import pandas as pd\n",
    "\n",
    "#format input\n",
    "input1='final_metabolic_table_s3.csv'\n",
    "\n",
    "#df1 = pd.read_csv(input1, index_col=0)\n",
    "#df2 = pd.read_csv(input2, index_col=0)\n",
    "#df = pd.concat([df1, df2.set_index(df1.index)], axis=1)\n",
    "df = pd.read_csv(input1, index_col=0)\n",
    "\n",
    "\n",
    "#import modules needed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#define what we want to predict out of the dataset\n",
    "predicting = 'C2_D.Galactose'\n",
    "#drop NAs (species we didn't measure specialism/generalism) from the dataset\n",
    "df = df.dropna(subset=[predicting])\n",
    "\n",
    "#decide what other data you want to drop from the input, here I am dropping the predicted value\n",
    "dropping = ['C2_D.Galactose', 'D.Galactose__Fermentation']\n",
    "input_ed = df.drop(dropping, axis=1)\n",
    "ml_input = np.array(input_ed) #array of input\n",
    "output = np.array(df[predicting]) #array of output\n",
    "print(output)\n",
    "\n",
    "#build your model \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "\n",
    "#use cross_val_predict to test the model and build the big confusion matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(model, ml_input, output, cv=10)\n",
    "conf_mat = confusion_matrix(output, y_pred)\n",
    "print(conf_mat)\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_mat, classes=['0','1'],\n",
    "                     title='Confusion matrix')\n",
    "plt.savefig(\"Confusion_Matrix.png\", dpi=200)\n",
    "\n",
    "\n",
    "#look specifically at which species are incorrectly and correctly predicted\n",
    "species_list = list(df.index)\n",
    "print('Incorrectly IDed  True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] != y_pred[i]:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "print('Correctly IDed   True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] == 1 and y_pred[i] == 1:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "\n",
    "header = list(input_ed.columns)\n",
    "\n",
    "# define the model again to re-test on a held out dataset, usually have  subsample=0.9, colsample_bynode=0.8, \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(ml_input, output, test_size=0.10)\n",
    "class_weights_training = compute_sample_weight('balanced', ytrain)\n",
    "#sample_weight=class_weights_training\n",
    "#model.fit(xtrain, ytrain) \n",
    "model.fit(xtrain, ytrain, sample_weight=class_weights_training) \n",
    "\n",
    "print('Mini_test')\n",
    "ypred = model.predict(xtest)\n",
    "cm = confusion_matrix(ytest,ypred)\n",
    "total = sum(cm[0]) + sum(cm[1])\n",
    "mis = cm[0][1] + cm[1][0]\n",
    "print('Misclassification rate:', mis/total)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=['0','1'],\n",
    "                     title='Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "#rebuild model yet again for the final big cross validation accuracy metrics with RepeatedStratifiedKFold\n",
    "classes_weights = compute_sample_weight('balanced', output)\n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "sample_weight=classes_weights\n",
    "model.fit(ml_input, output, sample_weight=classes_weights)\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, ml_input, output, scoring='accuracy', cv=cv)\n",
    "print(n_scores)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)), '\\n')\n",
    "\n",
    "\n",
    "#report feature importances in order of most important to least\n",
    "importance_list = []\n",
    "importances = list(model.feature_importances_)\n",
    "o = 0\n",
    "m = 0\n",
    "top10 = []\n",
    "for i in model.feature_importances_:\n",
    "    importance_list.append([i, header[o]])\n",
    "    o = o + 1\n",
    "for i in importance_list:\n",
    "    if i[0] == max(importances):\n",
    "        print(i[1], '\\t', i[0])\n",
    "        if m < 10:\n",
    "            top10.append(i[1])\n",
    "            m = m + 1\n",
    "            importances.remove(i[0])\n",
    "        else:\n",
    "            importances.remove(i[0])\n",
    "    else:\n",
    "        importance_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure S1: Predicting growth on galactose from environmental data--repeated for Xylose and Sucrose\n",
    "import pandas as pd\n",
    "\n",
    "#format input\n",
    "input1= 'final_env_table_s4.csv'\n",
    "input2='final_metabolic_table_s3.csv'\n",
    "\n",
    "df1 = pd.read_csv(input1, index_col=0)\n",
    "df2 = pd.read_csv(input2, index_col=0)\n",
    "df = pd.concat([df1, df2.set_index(df1.index)], axis=1)\n",
    "#df = pd.read_csv(input2, index_col=0)\n",
    "\n",
    "\n",
    "#import modules needed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#define what we want to predict out of the dataset\n",
    "predicting = 'C2_D.Galactose'\n",
    "#drop NAs (species we didn't measure specialism/generalism) from the dataset\n",
    "df = df.dropna(subset=[predicting])\n",
    "\n",
    "#decide what other data you want to drop from the input, here I am dropping the predicted value\n",
    "dropping = ['D.Glucose__Fermentation', 'D.Galactose__Fermentation', 'Maltose__Fermentation', 'Me_a.D.Glucoside__Fermentation', 'Sucrose__Fermentation', 'a_a.Trehalose__Fermentation', 'Melibiose__Fermentation', 'Lactose__Fermentation', 'Cellobiose__Fermentation', 'Melezitose__Fermentation', 'Raffinose__Fermentation', 'Inulin__Fermentation', 'Starch__Fermentation', 'D.Xylose__Fermentation', 'X_50__D.Glucose__O4_', 'X_60__D.Glucose__O5_', 'Starch_formation__M1_', 'Acid_acetic_production__M2_', 'Urea_hydrolysis__M3_', 'Diazonium_Blue_B_reaction__M4_', 'Methanol__assimilation', 'Ethanol__assimilation', 'C1_D.Glucose', 'C2_D.Galactose', 'C3_L.Sorbose', 'C4_D.Glucosamine', 'C5_D.Ribose', 'C6_D.Xylose', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C9_L.Rhamnose', 'C10_Sucrose', 'C11_Maltose', 'C12_a_a.Trehalose', 'C13_Me_a.D.Glucoside', 'C14_Cellobiose', 'C15_Salicin', 'C16_Arbutin', 'C17_Melibiose', 'C18_Lactose', 'C19_Raffinose', 'C20_Melezitose', 'C21_Inulin', 'C22_Starch', 'C23_Glycerol', 'C24_Erythritol', 'C25_Ribitol', 'C26_Xylitol', 'C27_L.Arabinitol', 'C28_D.Glucitol', 'C29_D.Mannitol', 'C30_Galactitol', 'C31_myo.Inositol', 'C32_D.Glucono.1_5.lactone', 'C33_2.Keto.D.Gluconate', 'C34_5.Keto.D.Gluconate', 'C35_D.Gluconate', 'C36_D.Glucuronate', 'C37_D.Galacturonate', 'C38_DL.Lactate', 'C39_Succinate', 'C40_Citrate', 'C43_Propane_1_2_diol', 'C44_Butane_2_3_diol', 'C45_Quinic_acid', 'C46_D.glucarate', 'C47_D.Galactonate', 'C48_Palatinose', 'C49_Levulinate', 'C50_L.Malic_acid', 'C51_L.Tartaric_acid', 'C52_D.Tartaric_acid', 'C53_meso.Tartaric_acid', 'C54_Galactaric_acid', 'C55_Uric_acid', 'C56_Gentobiose', 'C57_Ethylene_glycol', 'C58_Tween_40', 'C59_Tween_60', 'C60_Tween_80', 'N1_Nitrate', 'N2_Nitrite', 'N3_Ethylamine', 'N4_L.Lysine', 'N5_Cadaverine', 'N6_Creatine', 'N7_Creatinine', 'N8_Glucosamine', 'N9_Imidazole', 'N10_D.Tryptophan', 'N11_D.Proline', 'N12_Putrescine', 'V1_w_o_vitamins', 'V2_w_o_myo.Inositol', 'V3_w_o_Pantothenate', 'V4_w_o_Biotin', 'V5_w_o_Thiamin', 'V6_w_o_Biotin___Thiamin', 'V7_w_o_Pyridoxine', 'V8_w_o_Pyridoxine___Thiamin', 'V9_w_o_Niacin', 'V10_w_o_PABA', 'O1_Cycloheximide_0.01_', 'O2_Cycloheximide_0.1_', 'O3_Acetic_acid_1_', 'O6_10__NaCl', 'O7_16__NaCl', 'O8_Growth_at_pH_3', 'O9_Growth_at_pH_9.5', 'O10_Fluconazole', 'at_4_C', 'at_12_C', 'at_15_C', 'at_18_C', 'at_21_C', 'at_25_C', 'at_30_C', 'at_35_C', 'at_37_C', 'at_40_C', 'at_42_C', 'at_45_C']\n",
    "input_ed = df.drop(dropping, axis=1)\n",
    "#input_ed = df.drop(['C2_D.Galactose', 'D.Galactose__Fermentation'], axis=1)\n",
    "ml_input = np.array(input_ed) #array of input\n",
    "output = np.array(df[predicting]) #array of output\n",
    "print(output)\n",
    "\n",
    "#build your model \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "\n",
    "#use cross_val_predict to test the model and build the big confusion matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(model, ml_input, output, cv=10)\n",
    "conf_mat = confusion_matrix(output, y_pred)\n",
    "print(conf_mat)\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_mat, classes=['0','1'],\n",
    "                     title='Confusion matrix')\n",
    "plt.savefig(\"Confusion_Matrix.png\", dpi=200)\n",
    "\n",
    "\n",
    "#look specifically at which species are incorrectly and correctly predicted\n",
    "species_list = list(df.index)\n",
    "print('Incorrectly IDed  True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] != y_pred[i]:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "print('Correctly IDed   True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] == 1 and y_pred[i] == 1:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "\n",
    "header = list(input_ed.columns)\n",
    "\n",
    "# define the model again to re-test on a held out dataset, usually have  subsample=0.9, colsample_bynode=0.8, \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(ml_input, output, test_size=0.10)\n",
    "class_weights_training = compute_sample_weight('balanced', ytrain)\n",
    "#sample_weight=class_weights_training\n",
    "#model.fit(xtrain, ytrain) \n",
    "model.fit(xtrain, ytrain, sample_weight=class_weights_training) \n",
    "\n",
    "print('Mini_test')\n",
    "ypred = model.predict(xtest)\n",
    "cm = confusion_matrix(ytest,ypred)\n",
    "total = sum(cm[0]) + sum(cm[1])\n",
    "mis = cm[0][1] + cm[1][0]\n",
    "print('Misclassification rate:', mis/total)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=['0','1'],\n",
    "                     title='Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "#rebuild model yet again for the final big cross validation accuracy metrics with RepeatedStratifiedKFold\n",
    "classes_weights = compute_sample_weight('balanced', output)\n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "sample_weight=classes_weights\n",
    "model.fit(ml_input, output, sample_weight=classes_weights)\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, ml_input, output, scoring='accuracy', cv=cv)\n",
    "print(n_scores)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)), '\\n')\n",
    "\n",
    "\n",
    "#report feature importances in order of most important to least\n",
    "importance_list = []\n",
    "importances = list(model.feature_importances_)\n",
    "o = 0\n",
    "m = 0\n",
    "top10 = []\n",
    "for i in model.feature_importances_:\n",
    "    importance_list.append([i, header[o]])\n",
    "    o = o + 1\n",
    "for i in importance_list:\n",
    "    if i[0] == max(importances):\n",
    "        print(i[1], '\\t', i[0])\n",
    "        if m < 10:\n",
    "            top10.append(i[1])\n",
    "            m = m + 1\n",
    "            importances.remove(i[0])\n",
    "        else:\n",
    "            importances.remove(i[0])\n",
    "    else:\n",
    "        importance_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 5: Predicting growth on galactose from just the GAL genes\n",
    "import pandas as pd\n",
    "\n",
    "#format input\n",
    "input1= 'GAL_genes.csv'\n",
    "input2='final_metabolic_table_s3.csv'\n",
    "\n",
    "df1 = pd.read_csv(input1, index_col=0)\n",
    "df2 = pd.read_csv(input2, index_col=0)\n",
    "df = pd.concat([df1, df2.set_index(df1.index)], axis=1)\n",
    "#df = pd.read_csv(input2, index_col=0)\n",
    "\n",
    "\n",
    "#import modules needed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#define what we want to predict out of the dataset\n",
    "predicting = 'C2_D.Galactose'\n",
    "#drop NAs (species we didn't measure specialism/generalism) from the dataset\n",
    "df = df.dropna(subset=[predicting])\n",
    "\n",
    "#decide what other data you want to drop from the input, here I am dropping the predicted value\n",
    "dropping = ['D.Glucose__Fermentation', 'D.Galactose__Fermentation', 'Maltose__Fermentation', 'Me_a.D.Glucoside__Fermentation', 'Sucrose__Fermentation', 'a_a.Trehalose__Fermentation', 'Melibiose__Fermentation', 'Lactose__Fermentation', 'Cellobiose__Fermentation', 'Melezitose__Fermentation', 'Raffinose__Fermentation', 'Inulin__Fermentation', 'Starch__Fermentation', 'D.Xylose__Fermentation', 'X_50__D.Glucose__O4_', 'X_60__D.Glucose__O5_', 'Starch_formation__M1_', 'Acid_acetic_production__M2_', 'Urea_hydrolysis__M3_', 'Diazonium_Blue_B_reaction__M4_', 'Methanol__assimilation', 'Ethanol__assimilation', 'C1_D.Glucose', 'C2_D.Galactose', 'C3_L.Sorbose', 'C4_D.Glucosamine', 'C5_D.Ribose', 'C6_D.Xylose', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C9_L.Rhamnose', 'C10_Sucrose', 'C11_Maltose', 'C12_a_a.Trehalose', 'C13_Me_a.D.Glucoside', 'C14_Cellobiose', 'C15_Salicin', 'C16_Arbutin', 'C17_Melibiose', 'C18_Lactose', 'C19_Raffinose', 'C20_Melezitose', 'C21_Inulin', 'C22_Starch', 'C23_Glycerol', 'C24_Erythritol', 'C25_Ribitol', 'C26_Xylitol', 'C27_L.Arabinitol', 'C28_D.Glucitol', 'C29_D.Mannitol', 'C30_Galactitol', 'C31_myo.Inositol', 'C32_D.Glucono.1_5.lactone', 'C33_2.Keto.D.Gluconate', 'C34_5.Keto.D.Gluconate', 'C35_D.Gluconate', 'C36_D.Glucuronate', 'C37_D.Galacturonate', 'C38_DL.Lactate', 'C39_Succinate', 'C40_Citrate', 'C43_Propane_1_2_diol', 'C44_Butane_2_3_diol', 'C45_Quinic_acid', 'C46_D.glucarate', 'C47_D.Galactonate', 'C48_Palatinose', 'C49_Levulinate', 'C50_L.Malic_acid', 'C51_L.Tartaric_acid', 'C52_D.Tartaric_acid', 'C53_meso.Tartaric_acid', 'C54_Galactaric_acid', 'C55_Uric_acid', 'C56_Gentobiose', 'C57_Ethylene_glycol', 'C58_Tween_40', 'C59_Tween_60', 'C60_Tween_80', 'N1_Nitrate', 'N2_Nitrite', 'N3_Ethylamine', 'N4_L.Lysine', 'N5_Cadaverine', 'N6_Creatine', 'N7_Creatinine', 'N8_Glucosamine', 'N9_Imidazole', 'N10_D.Tryptophan', 'N11_D.Proline', 'N12_Putrescine', 'V1_w_o_vitamins', 'V2_w_o_myo.Inositol', 'V3_w_o_Pantothenate', 'V4_w_o_Biotin', 'V5_w_o_Thiamin', 'V6_w_o_Biotin___Thiamin', 'V7_w_o_Pyridoxine', 'V8_w_o_Pyridoxine___Thiamin', 'V9_w_o_Niacin', 'V10_w_o_PABA', 'O1_Cycloheximide_0.01_', 'O2_Cycloheximide_0.1_', 'O3_Acetic_acid_1_', 'O6_10__NaCl', 'O7_16__NaCl', 'O8_Growth_at_pH_3', 'O9_Growth_at_pH_9.5', 'O10_Fluconazole', 'at_4_C', 'at_12_C', 'at_15_C', 'at_18_C', 'at_21_C', 'at_25_C', 'at_30_C', 'at_35_C', 'at_37_C', 'at_40_C', 'at_42_C', 'at_45_C']\n",
    "input_ed = df.drop(dropping, axis=1)\n",
    "#input_ed = df.drop(['C2_D.Galactose', 'D.Galactose__Fermentation'], axis=1)\n",
    "ml_input = np.array(input_ed) #array of input\n",
    "output = np.array(df[predicting]) #array of output\n",
    "print(output)\n",
    "\n",
    "#build your model \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "\n",
    "#use cross_val_predict to test the model and build the big confusion matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(model, ml_input, output, cv=10)\n",
    "conf_mat = confusion_matrix(output, y_pred)\n",
    "print(conf_mat)\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_mat, classes=['0','1'],\n",
    "                     title='Confusion matrix')\n",
    "plt.savefig(\"Confusion_Matrix.png\", dpi=200)\n",
    "\n",
    "\n",
    "#look specifically at which species are incorrectly and correctly predicted\n",
    "species_list = list(df.index)\n",
    "print('Incorrectly IDed  True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] != y_pred[i]:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "print('Correctly IDed   True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] == 1 and y_pred[i] == 1:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "\n",
    "header = list(input_ed.columns)\n",
    "\n",
    "# define the model again to re-test on a held out dataset, usually have  subsample=0.9, colsample_bynode=0.8, \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(ml_input, output, test_size=0.10)\n",
    "class_weights_training = compute_sample_weight('balanced', ytrain)\n",
    "#sample_weight=class_weights_training\n",
    "#model.fit(xtrain, ytrain) \n",
    "model.fit(xtrain, ytrain, sample_weight=class_weights_training) \n",
    "\n",
    "print('Mini_test')\n",
    "ypred = model.predict(xtest)\n",
    "cm = confusion_matrix(ytest,ypred)\n",
    "total = sum(cm[0]) + sum(cm[1])\n",
    "mis = cm[0][1] + cm[1][0]\n",
    "print('Misclassification rate:', mis/total)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=['0','1'],\n",
    "                     title='Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "#rebuild model yet again for the final big cross validation accuracy metrics with RepeatedStratifiedKFold\n",
    "classes_weights = compute_sample_weight('balanced', output)\n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "sample_weight=classes_weights\n",
    "model.fit(ml_input, output, sample_weight=classes_weights)\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, ml_input, output, scoring='accuracy', cv=cv)\n",
    "print(n_scores)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)), '\\n')\n",
    "\n",
    "\n",
    "#report feature importances in order of most important to least\n",
    "importance_list = []\n",
    "importances = list(model.feature_importances_)\n",
    "o = 0\n",
    "m = 0\n",
    "top10 = []\n",
    "for i in model.feature_importances_:\n",
    "    importance_list.append([i, header[o]])\n",
    "    o = o + 1\n",
    "for i in importance_list:\n",
    "    if i[0] == max(importances):\n",
    "        print(i[1], '\\t', i[0])\n",
    "        if m < 10:\n",
    "            top10.append(i[1])\n",
    "            m = m + 1\n",
    "            importances.remove(i[0])\n",
    "        else:\n",
    "            importances.remove(i[0])\n",
    "    else:\n",
    "        importance_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 5: Predicting growth on galactose from GAL genes and metabolic data\n",
    "import pandas as pd\n",
    "\n",
    "#format input\n",
    "input1= 'GAL_genes.csv'\n",
    "input2='final_metabolic_table_s3.csv'\n",
    "\n",
    "df1 = pd.read_csv(input1, index_col=0)\n",
    "df2 = pd.read_csv(input2, index_col=0)\n",
    "df = pd.concat([df1, df2.set_index(df1.index)], axis=1)\n",
    "#df = pd.read_csv(input2, index_col=0)\n",
    "\n",
    "\n",
    "#import modules needed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#define what we want to predict out of the dataset\n",
    "predicting = 'C2_D.Galactose'\n",
    "#drop NAs (species we didn't measure specialism/generalism) from the dataset\n",
    "df = df.dropna(subset=[predicting])\n",
    "\n",
    "#decide what other data you want to drop from the input, here I am dropping the predicted value\n",
    "dropping = ['C2_D.Galactose', 'D.Galactose__Fermentation']\n",
    "input_ed = df.drop(dropping, axis=1)\n",
    "#input_ed = df.drop(['C2_D.Galactose', 'D.Galactose__Fermentation'], axis=1)\n",
    "ml_input = np.array(input_ed) #array of input\n",
    "output = np.array(df[predicting]) #array of output\n",
    "print(output)\n",
    "\n",
    "#build your model \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "\n",
    "#use cross_val_predict to test the model and build the big confusion matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(model, ml_input, output, cv=10)\n",
    "conf_mat = confusion_matrix(output, y_pred)\n",
    "print(conf_mat)\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_mat, classes=['0','1'],\n",
    "                     title='Confusion matrix')\n",
    "plt.savefig(\"Confusion_Matrix.png\", dpi=200)\n",
    "\n",
    "\n",
    "#look specifically at which species are incorrectly and correctly predicted\n",
    "species_list = list(df.index)\n",
    "print('Incorrectly IDed  True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] != y_pred[i]:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "print('Correctly IDed   True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] == 1 and y_pred[i] == 1:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "\n",
    "header = list(input_ed.columns)\n",
    "\n",
    "# define the model again to re-test on a held out dataset, usually have  subsample=0.9, colsample_bynode=0.8, \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(ml_input, output, test_size=0.10)\n",
    "class_weights_training = compute_sample_weight('balanced', ytrain)\n",
    "#sample_weight=class_weights_training\n",
    "#model.fit(xtrain, ytrain) \n",
    "model.fit(xtrain, ytrain, sample_weight=class_weights_training) \n",
    "\n",
    "print('Mini_test')\n",
    "ypred = model.predict(xtest)\n",
    "cm = confusion_matrix(ytest,ypred)\n",
    "total = sum(cm[0]) + sum(cm[1])\n",
    "mis = cm[0][1] + cm[1][0]\n",
    "print('Misclassification rate:', mis/total)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=['0','1'],\n",
    "                     title='Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "#rebuild model yet again for the final big cross validation accuracy metrics with RepeatedStratifiedKFold\n",
    "classes_weights = compute_sample_weight('balanced', output)\n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "sample_weight=classes_weights\n",
    "model.fit(ml_input, output, sample_weight=classes_weights)\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, ml_input, output, scoring='accuracy', cv=cv)\n",
    "print(n_scores)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)), '\\n')\n",
    "\n",
    "\n",
    "#report feature importances in order of most important to least\n",
    "importance_list = []\n",
    "importances = list(model.feature_importances_)\n",
    "o = 0\n",
    "m = 0\n",
    "top10 = []\n",
    "for i in model.feature_importances_:\n",
    "    importance_list.append([i, header[o]])\n",
    "    o = o + 1\n",
    "for i in importance_list:\n",
    "    if i[0] == max(importances):\n",
    "        print(i[1], '\\t', i[0])\n",
    "        if m < 10:\n",
    "            top10.append(i[1])\n",
    "            m = m + 1\n",
    "            importances.remove(i[0])\n",
    "        else:\n",
    "            importances.remove(i[0])\n",
    "    else:\n",
    "        importance_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 6: Predicting growth on galactose from GAL genes and galactitol\n",
    "import pandas as pd\n",
    "\n",
    "#format input\n",
    "input1= 'GAL_genes.csv'\n",
    "input2='final_metabolic_table_s3.csv'\n",
    "\n",
    "df1 = pd.read_csv(input1, index_col=0)\n",
    "df2 = pd.read_csv(input2, index_col=0)\n",
    "df = pd.concat([df1, df2.set_index(df1.index)], axis=1)\n",
    "#df = pd.read_csv(input2, index_col=0)\n",
    "\n",
    "\n",
    "#import modules needed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#define what we want to predict out of the dataset\n",
    "predicting = 'C2_D.Galactose'\n",
    "#drop NAs (species we didn't measure specialism/generalism) from the dataset\n",
    "df = df.dropna(subset=[predicting])\n",
    "\n",
    "#decide what other data you want to drop from the input, here I am dropping the predicted value\n",
    "dropping = ['D.Glucose__Fermentation', 'D.Galactose__Fermentation', 'Maltose__Fermentation', 'Me_a.D.Glucoside__Fermentation', 'Sucrose__Fermentation', 'a_a.Trehalose__Fermentation', 'Melibiose__Fermentation', 'Lactose__Fermentation', 'Cellobiose__Fermentation', 'Melezitose__Fermentation', 'Raffinose__Fermentation', 'Inulin__Fermentation', 'Starch__Fermentation', 'D.Xylose__Fermentation', 'X_50__D.Glucose__O4_', 'X_60__D.Glucose__O5_', 'Starch_formation__M1_', 'Acid_acetic_production__M2_', 'Urea_hydrolysis__M3_', 'Diazonium_Blue_B_reaction__M4_', 'Methanol__assimilation', 'Ethanol__assimilation', 'C1_D.Glucose', 'C2_D.Galactose', 'C3_L.Sorbose', 'C4_D.Glucosamine', 'C5_D.Ribose', 'C6_D.Xylose', 'C7_L.Arabinose', 'C8_D.Arabinose', 'C9_L.Rhamnose', 'C10_Sucrose', 'C11_Maltose', 'C12_a_a.Trehalose', 'C13_Me_a.D.Glucoside', 'C14_Cellobiose', 'C15_Salicin', 'C16_Arbutin', 'C17_Melibiose', 'C18_Lactose', 'C19_Raffinose', 'C20_Melezitose', 'C21_Inulin', 'C22_Starch', 'C23_Glycerol', 'C24_Erythritol', 'C25_Ribitol', 'C26_Xylitol', 'C27_L.Arabinitol', 'C28_D.Glucitol', 'C29_D.Mannitol', 'C31_myo.Inositol', 'C32_D.Glucono.1_5.lactone', 'C33_2.Keto.D.Gluconate', 'C34_5.Keto.D.Gluconate', 'C35_D.Gluconate', 'C36_D.Glucuronate', 'C37_D.Galacturonate', 'C38_DL.Lactate', 'C39_Succinate', 'C40_Citrate', 'C43_Propane_1_2_diol', 'C44_Butane_2_3_diol', 'C45_Quinic_acid', 'C46_D.glucarate', 'C47_D.Galactonate', 'C48_Palatinose', 'C49_Levulinate', 'C50_L.Malic_acid', 'C51_L.Tartaric_acid', 'C52_D.Tartaric_acid', 'C53_meso.Tartaric_acid', 'C54_Galactaric_acid', 'C55_Uric_acid', 'C56_Gentobiose', 'C57_Ethylene_glycol', 'C58_Tween_40', 'C59_Tween_60', 'C60_Tween_80', 'N1_Nitrate', 'N2_Nitrite', 'N3_Ethylamine', 'N4_L.Lysine', 'N5_Cadaverine', 'N6_Creatine', 'N7_Creatinine', 'N8_Glucosamine', 'N9_Imidazole', 'N10_D.Tryptophan', 'N11_D.Proline', 'N12_Putrescine', 'V1_w_o_vitamins', 'V2_w_o_myo.Inositol', 'V3_w_o_Pantothenate', 'V4_w_o_Biotin', 'V5_w_o_Thiamin', 'V6_w_o_Biotin___Thiamin', 'V7_w_o_Pyridoxine', 'V8_w_o_Pyridoxine___Thiamin', 'V9_w_o_Niacin', 'V10_w_o_PABA', 'O1_Cycloheximide_0.01_', 'O2_Cycloheximide_0.1_', 'O3_Acetic_acid_1_', 'O6_10__NaCl', 'O7_16__NaCl', 'O8_Growth_at_pH_3', 'O9_Growth_at_pH_9.5', 'O10_Fluconazole', 'at_4_C', 'at_12_C', 'at_15_C', 'at_18_C', 'at_21_C', 'at_25_C', 'at_30_C', 'at_35_C', 'at_37_C', 'at_40_C', 'at_42_C', 'at_45_C']\n",
    "input_ed = df.drop(dropping, axis=1)\n",
    "#input_ed = df.drop(['C2_D.Galactose', 'D.Galactose__Fermentation'], axis=1)\n",
    "ml_input = np.array(input_ed) #array of input\n",
    "output = np.array(df[predicting]) #array of output\n",
    "print(output)\n",
    "\n",
    "#build your model \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "\n",
    "#use cross_val_predict to test the model and build the big confusion matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(model, ml_input, output, cv=10)\n",
    "conf_mat = confusion_matrix(output, y_pred)\n",
    "print(conf_mat)\n",
    "plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_mat, classes=['0','1'],\n",
    "                     title='Confusion matrix')\n",
    "plt.savefig(\"Confusion_Matrix.png\", dpi=200)\n",
    "\n",
    "\n",
    "#look specifically at which species are incorrectly and correctly predicted\n",
    "species_list = list(df.index)\n",
    "print('Incorrectly IDed  True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] != y_pred[i]:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "print('Correctly IDed   True_Value  Predicted_Value')\n",
    "for i in range(0, len(species_list)):\n",
    "    if output[i] == 1 and y_pred[i] == 1:\n",
    "        print(species_list[i], output[i], y_pred[i])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "\n",
    "header = list(input_ed.columns)\n",
    "\n",
    "# define the model again to re-test on a held out dataset, usually have  subsample=0.9, colsample_bynode=0.8, \n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "xtrain, xtest, ytrain, ytest=train_test_split(ml_input, output, test_size=0.10)\n",
    "class_weights_training = compute_sample_weight('balanced', ytrain)\n",
    "#sample_weight=class_weights_training\n",
    "#model.fit(xtrain, ytrain) \n",
    "model.fit(xtrain, ytrain, sample_weight=class_weights_training) \n",
    "\n",
    "print('Mini_test')\n",
    "ypred = model.predict(xtest)\n",
    "cm = confusion_matrix(ytest,ypred)\n",
    "total = sum(cm[0]) + sum(cm[1])\n",
    "mis = cm[0][1] + cm[1][0]\n",
    "print('Misclassification rate:', mis/total)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=['0','1'],\n",
    "                     title='Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "#rebuild model yet again for the final big cross validation accuracy metrics with RepeatedStratifiedKFold\n",
    "classes_weights = compute_sample_weight('balanced', output)\n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs = 8)\n",
    "sample_weight=classes_weights\n",
    "model.fit(ml_input, output, sample_weight=classes_weights)\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, ml_input, output, scoring='accuracy', cv=cv)\n",
    "print(n_scores)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)), '\\n')\n",
    "\n",
    "\n",
    "#report feature importances in order of most important to least\n",
    "importance_list = []\n",
    "importances = list(model.feature_importances_)\n",
    "o = 0\n",
    "m = 0\n",
    "top10 = []\n",
    "for i in model.feature_importances_:\n",
    "    importance_list.append([i, header[o]])\n",
    "    o = o + 1\n",
    "for i in importance_list:\n",
    "    if i[0] == max(importances):\n",
    "        print(i[1], '\\t', i[0])\n",
    "        if m < 10:\n",
    "            top10.append(i[1])\n",
    "            m = m + 1\n",
    "            importances.remove(i[0])\n",
    "        else:\n",
    "            importances.remove(i[0])\n",
    "    else:\n",
    "        importance_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC AUC code: plug in input files, predicting variable, and dropping variables.\n",
    "#example here is growth on galactose predicted from metabolic data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "df = pd.read_csv('final_metabolic_table_s3.csv', index_col=0)\n",
    "predicting = 'C2_D.Galactose'\n",
    "df = df.dropna(subset=[predicting])\n",
    "input_ed = df.drop(['C2_D.Galactose', 'D.Galactose__Fermentation'], axis=1)\n",
    "X = np.array(input_ed) #array of input\n",
    "y = np.array(df[predicting])\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss', n_jobs=8)\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    model = XGBRFClassifier(max_depth=12, n_estimators=100, use_label_encoder =False,  eval_metric='mlogloss',  n_jobs=8)\n",
    "    model.fit(X[train], y[train])\n",
    "    y_score = model.predict_proba(X[test])\n",
    "    fpr, tpr, _ = roc_curve(y[test], y_score[:, 1])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "    tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    tpr[0] = 0.0\n",
    "    tprs.append(tpr)\n",
    "\n",
    "tprs = np.array(tprs)\n",
    "mean_tprs = tprs.mean(axis=0)\n",
    "aucs = np.array(aucs)\n",
    "mean_auc = aucs.mean(axis=0)\n",
    "std = tprs.std(axis=0)\n",
    "\n",
    "tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "tprs_lower = mean_tprs - std\n",
    "\n",
    "\n",
    "plt.plot(base_fpr, mean_tprs, 'b', label = 'Mean ROC (AUC = %0.2f)' % mean_auc )\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3, label=r\"$\\pm$ 1 std. dev.\")\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--', label=\"Chance\")\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig(\"gen_spec.png\", dpi=500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-data-science-xgb",
   "language": "python",
   "name": "py3-data-science-xgb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
